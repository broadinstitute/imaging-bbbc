{% extends 'base.html' %}
{% block content %}

<p class="small">Accession number <a href="">{{acc}}</a> &middot; Version 1</p>

<h3>Example images</h3>

<ul class="thumbnails">
  <li>
    <div class="thumbnail">
      <img src="example_vglut1.jpg" width="" height="250" alt="example image"/>
    </div>
  </li>
  <li>
    <div class="thumbnail">
      <img src="example_vgat.jpg" width="" height="250" alt="example image"/>
    </div>
  </li>
</ul>

    <h3>Description of the biological application</h3>
    <p>These images are of mouse hippocampal presynaptic terminals and the goal is to extract presynaptic terminals' densities.</p>
    <p>The presented seet of images were being used to validate the accuracy of automatic detection and counting methods</p>

    <h3>Images</h3>

    <p>Sections were directly analyzed with a Zeiss LSM 710 Confocal microscope. Fluorescently labeled profiles were examined through separate channels, using excitation peaks of 401, 488, 594 and 634 nm to visualize DAPI, vGlut-1 EGFP, NeuN and vGat, respectively. Consecutive stacks of images, at high magnification (63×; oil immersion), using tile scan mode, were acquired in the hippocampal region. Each stack was composed by 15 images (0.14 μm z-step) of 1024 × 1024 pixels (8 bit). Confocal parameters were set so that the fluorescence signal was as bright as possible while ensuring that there were no saturated pixels.</p>

    <p>12 stacks (1024x1024x15) were selected for validation (6 vGlut-1 and 6 vGat). Original images are 8-bit TIFF files.</p>
    <p>
      <a href="BBBC043_v1_original_images.zip"><i class="icon-download-alt"></i> BBBC043_v1_original_images.zip (126 MB)</a>
    </p>

    <h3>Ground truth {{C}}</h3>
    <p>12 stacks of 15 images (6 vGlut-1 and 6 vGat) were partially labeled by two experts. The experts were asked to mark with a point every puncta centroids they saw in a bounded rectangular region of the stack.</p>
    <p>The ground truth is provided both as an ImageJ overlay over the original image and as two additional color channels, one marking the centroids the other showing the region involved in the validation. Files are provided as RGB images, where R = original image, G = expert's centroids, B = region of the validation.</p>
    <p>The coordinates of the expert's centroids are also provided as csv files.</p>
    <p>Moreover the counts of the two experts are provided in a single csv file.</p>

    <p>The entire stack can be used by the algorithm to detect the objects but the validation is performed just on the given region.</p>

    <p>To validate an object detection algorithm compute precision and recall for each of the two experts. For that consider an object as correctly detected if a point given by the expert lies inside one of the objects detected by the algorithm, obviously without associating in this way more than one point with the same object. Then, compute precision as the fraction of correctly detected objects over the total number of objects detected by the algorithm. Recall is the fraction of correctly detected objects over the total number of objects identified by the expert.</p>
    <p>The F1 score, that is, the harmonic mean of precision and recall, is used as a summarizing measure.</p>

    <p>To validate a counting algorithm just compare for every stack the number of objects estimated in the validation regions with the mean count of the two experts and compute the average relative error between the two values.
    The average relative errors for the two experts is <strong>0.29</strong> (<strong>0.2 for the vGlut-1</strong> marker and <strong>0.38 for the vGat</strong> marker).</p>

    <p><a href="BBBC043_v1_validation.zip"><i class="icon-download-alt"></i> BBBC043_v1_validation.zip (325 Mb)</a></p>

    <h3>For more information</h3>
    <p>Please contact <a href="mailto:gherardo.varando@upm.es">Gherardo Varando</a> regarding this dataset.</p>

    <h3>Published results using this image set</h3>
    <p>Varando G, et al. MultiMap: A Tool to Automatically Extract and Analyse Spatial Microscopic Data From Large Stacks of Confocal Microscopy Images. Front. Neuroanat. 2018;12:37. doi:<a href="https://doi.org/10.3389/fnana.2018.00037">10.3389/fnana.2018.00037</a>. PMCID: PMC5974206 </p>
    <h3>Recommended citation</h3>
    <p>&quot;We used image set <a href="">{{acc}}v1</a> Varando G. et al., available from the Broad Bioimage Benchmark Collection
      [<a href="http://dx.doi.org/10.1038/nmeth.2083">Ljosa et al., <i>Nature Methods</i>, 2012</a>].&quot;</p>
    <h3>Copyright</h3>

    <p><a href="http://creativecommons.org/licenses/by-nc-sa/3.0/" rel="license"><img alt="CC0" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png"></a> The images and ground truth are licensed under a
    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a> by <a href="mailto:gherardo.varando@upm.es">Gherardo Varando</a>, <a href="mailto:rbp@cajal.csic.es">Ruth Benavides-Piccione </a>, <a href="mailto:amunozc@bio.ucm.es"> Alberto Muñoz</a>, <a href="mailto:kastanauskaite@gmail.com"> Asta Kastanauskaite</a>.</p>

  <footer class="footer">
        <p>This page last updated 2019-04-05</p>
  </footer>


{% endblock %}
